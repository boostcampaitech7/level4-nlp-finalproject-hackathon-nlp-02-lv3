from audiocraft.models import musicgen
import torchaudio
import yaml
import os
import csv
import time  # âœ… ì¬ìƒì„± ì‹œ ê³¼ë¶€í•˜ ë°©ì§€ìš©
from tqdm import tqdm
import torch
from evaluate_clap_mood_similarity import evaluate_audio_mood_scores  # âœ… CLAP í‰ê°€ í•¨ìˆ˜ ì„í¬íŠ¸

# YAML íŒŒì¼ ì½ê¸°
with open("config.yaml", "r") as file:
    config = yaml.safe_load(file)

# ì„¤ì • ê°’ ê°€ì ¸ì˜¤ê¸°
input_csv   = config["input_csv"]
output_dir  = config["output_dir"]
duration_sec= config["duration_sec"]
model_size  = config["model_size"]
positive_threshold = 0.6  # âœ… positive_mood ì ìˆ˜ê°€ 0.6 ì´ìƒì´ì–´ì•¼ í•¨
max_retries = 3  # âœ… ìµœëŒ€ ì¬ìƒì„± íšŸìˆ˜

# GPU device ë²ˆí˜¸ë¥¼ ì½”ë“œ ë‚´ì—ì„œ ì§ì ‘ ì„¤ì • (ì˜ˆ: 0ë²ˆ GPU ì‚¬ìš©)
gpu_device_index = 1  # ì›í•˜ëŠ” GPU ë²ˆí˜¸ë¥¼ ì—¬ê¸°ì— ì§€ì • (ì˜ˆ: 0 ë˜ëŠ” 1)
torch.cuda.set_device(gpu_device_index)
device_for_model = "cuda"  # autocast ë“± ë‚´ë¶€ ëª¨ë“ˆì€ "cuda"ë§Œ í—ˆìš©í•©ë‹ˆë‹¤.

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(output_dir, exist_ok=True)

# ëª¨ë¸ ë¡œë“œ (ì§€ì •í•œ GPU ì‚¬ìš©)
print(f"Loading model: {model_size} on GPU device {gpu_device_index}")
model = musicgen.MusicGen.get_pretrained(model_size, device=device_for_model)

# CSV íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì½ê¸°
with open(input_csv, newline='', encoding='utf-8') as csvfile:
    reader = list(csv.DictReader(csvfile))
    for row in tqdm(reader, desc="Generating music"):
        file_id     = row["id"]
        prompt_text = row["musicgen_input_text"]
        positive_mood = row["positive_mood"]
        negative_mood = row["negative_mood"]

        # ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •
        model.set_generation_params(duration=duration_sec)

        retry_count = 0
        while retry_count <= max_retries:
            # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŒì•… ìƒì„±
            res = model.generate([prompt_text], progress=True)

            # ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì €ì¥ (1D í…ì„œë¼ë©´ ë°°ì¹˜ ì°¨ì› ì¶”ê°€)
            audio_data = res[0]
            if audio_data.dim() == 1:
                audio_data = audio_data.unsqueeze(0)

            # íŒŒì¼ëª…ì€ id.wav ë¡œ ì €ì¥
            output_file = os.path.join(output_dir, f"{file_id}.wav")
            torchaudio.save(output_file, audio_data.cpu(), sample_rate=32000)
            print(f"ğŸµ Music saved as {output_file}")

            # âœ… ìƒì„±ëœ ìŒì•…ì˜ CLAP ì ìˆ˜ í‰ê°€
            mood_scores = evaluate_audio_mood_scores(output_file, positive_mood, negative_mood)

            if mood_scores:
                print(f"ğŸ” CLAP Scores - Positive: {mood_scores['positive_score']:.4f}, Negative: {mood_scores['negative_score']:.4f}")

                if mood_scores["positive_score"] >= positive_threshold:
                    print(f"âœ… Positive mood score ({mood_scores['positive_score']:.4f}) is above threshold. Keeping the file.")
                    break  # âœ… ë§Œì¡±í•˜ë©´ ë£¨í”„ ì¢…ë£Œ
                else:
                    print(f"âš ï¸ Positive mood score ({mood_scores['positive_score']:.4f}) is too low. Regenerating...")
                    retry_count += 1
                    os.remove(output_file)  # âŒ ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ íŒŒì¼ ì‚­ì œ
                    time.sleep(1)

        if retry_count > max_retries:
            print(f"ğŸš¨ Maximum retries reached. Keeping last generated file ({output_file}) with low positive score.")
