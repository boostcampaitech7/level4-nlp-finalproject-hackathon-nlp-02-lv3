import logging
import os

from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
from config import ACCESS_KEY, CLOVA_API_KEY, SECRET_KEY
from modules import (
    CompletionExecutor,
    create_finetuning_task,
    generate_ads_comparison,
    generate_qa_data_with_comparison,
    upload_file_to_s3,
)
import pandas as pd


# âœ… ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CSV_FILE_PATH = os.path.join(BASE_DIR, "generated_ad_copies_with_likes.csv")
OUTPUT_CSV_PATH = os.path.join(BASE_DIR, "hyperclovax_ab_feedback_dataset.csv")

# âœ… ë¡œê·¸ ì„¤ì •
logging.basicConfig(level=logging.INFO)

# âœ… Airflow DAG ì •ì˜
dag = DAG(
    dag_id="ad_finetuning_pipeline",
    description="ê´‘ê³  ë¬¸êµ¬ ë¹„êµ ë° Fine-Tuning DAG",
    schedule_interval="@daily",
    start_date=days_ago(1),
    catchup=False,
)

# âœ… íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (BashOperator)
check_file = BashOperator(
    task_id="check_csv_file",
    bash_command=f"ls -l {CSV_FILE_PATH}",
    dag=dag,
)


# âœ… 1. ê´‘ê³  ë¬¸êµ¬ ë°ì´í„° ìƒì„±
def generate_ad_comparison_task():
    logging.info(f"ğŸ“Œ ê´‘ê³  ë¬¸êµ¬ ë¹„êµ ë°ì´í„° ìƒì„± ì‹œì‘, íŒŒì¼ ê²½ë¡œ: {CSV_FILE_PATH}")

    # íŒŒì¼ì´ DAG ì‹¤í–‰ í™˜ê²½ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸
    if not os.path.exists(CSV_FILE_PATH):
        raise FileNotFoundError(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {CSV_FILE_PATH}")

    try:
        ads_comparison = generate_ads_comparison(CSV_FILE_PATH)
        logging.info(f"âœ… ê´‘ê³  ë¬¸êµ¬ ë¹„êµ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(ads_comparison)}ê°œ")

        if len(ads_comparison) == 0:
            raise ValueError(
                "âŒ ê´‘ê³  ë¬¸êµ¬ ë¹„êµ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."
            )

        return ads_comparison

    except Exception as e:
        logging.error(f"âŒ ê´‘ê³  ë¬¸êµ¬ ë¹„êµ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise e


# âœ… 2. ëª¨ë¸ ì‹¤í–‰ ë° QA ë°ì´í„° ìƒì„±
def generate_qa_data_task(**kwargs):
    ads_comparison = kwargs["ti"].xcom_pull(task_ids="generate_ad_comparison")

    # ëª¨ë¸ ì‹¤í–‰
    completion_executor = CompletionExecutor(
        host="https://clovastudio.stream.ntruss.com",
        api_key=f"Bearer {CLOVA_API_KEY}",
        request_id="YOUR_REQUEST_ID",
    )

    qa_data = generate_qa_data_with_comparison(ads_comparison, completion_executor)

    # âœ… ì ˆëŒ€ ê²½ë¡œë¡œ ì €ì¥
    qa_df = pd.DataFrame(qa_data)
    qa_df.to_csv(OUTPUT_CSV_PATH, index=False, encoding="utf-8")
    logging.info(f"âœ… QA ë°ì´í„° CSV ì €ì¥ ì™„ë£Œ: {OUTPUT_CSV_PATH}")

    return OUTPUT_CSV_PATH


# âœ… 3. S3 ì—…ë¡œë“œ
def upload_to_s3_task(**kwargs):
    file_path = kwargs["ti"].xcom_pull(task_ids="generate_qa_data")

    success, message = upload_file_to_s3(
        file_path,
        "testtesttesttestetst",
        "hyperclovax_ab_feedback_dataset.csv",
        ACCESS_KEY,
        SECRET_KEY,
    )

    if not success:
        raise Exception(f"S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {message}")

    logging.info(f"âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ: {message}")


# âœ… 4. Fine-Tuning ìš”ì²­
def finetuning_task(**kwargs):
    dataset_file = "testtesttesttestetst/hyperclovax_ab_feedback_dataset.csv"
    finetuning_response = create_finetuning_task(
        task_name="My_Ad_Finetuning_Task",
        model="HCX-003",
        tuning_type="PEFT",
        task_type="GENERATION",
        train_epochs=10,
        learning_rate=1e-5,
        dataset_file=dataset_file,
        bucket_name="testtesttesttestetst",
        access_key=ACCESS_KEY,
        secret_key=SECRET_KEY,
        api_key=CLOVA_API_KEY,
    )

    logging.info(f"âœ… Fine-Tuning ì‘ë‹µ ê²°ê³¼: {finetuning_response}")


# âœ… Airflow íƒœìŠ¤í¬ ì •ì˜
generate_ad_comparison = PythonOperator(
    task_id="generate_ad_comparison",
    python_callable=generate_ad_comparison_task,
    dag=dag,
)

generate_qa_data = PythonOperator(
    task_id="generate_qa_data",
    python_callable=generate_qa_data_task,
    provide_context=True,
    dag=dag,
)

upload_to_s3 = PythonOperator(
    task_id="upload_to_s3",
    python_callable=upload_to_s3_task,
    provide_context=True,
    dag=dag,
)

finetuning = PythonOperator(
    task_id="finetuning",
    python_callable=finetuning_task,
    provide_context=True,
    dag=dag,
)

# âœ… íƒœìŠ¤í¬ ì‹¤í–‰ ìˆœì„œ ì •ì˜
check_file >> generate_ad_comparison >> generate_qa_data >> upload_to_s3 >> finetuning
