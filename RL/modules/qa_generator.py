import logging

import pandas as pd


# ë¡œê·¸ ì„¤ì •
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] - %(message)s",
    level=logging.INFO,  # ê¸°ë³¸ ë¡œê·¸ ë ˆë²¨ ì„¤ì • (DEBUGë¡œ ë³€ê²½ ê°€ëŠ¥)
    handlers=[
        logging.StreamHandler(),  # í„°ë¯¸ë„ ì¶œë ¥
        logging.FileHandler("qa_generation.log", mode="w", encoding="utf-8"),  # íŒŒì¼ ì €ì¥
    ],
)


def get_feedback_from_model(completion_executor, ad1_text, ad2_text, ad1_likes, ad2_likes):
    """ëª¨ë¸ í”¼ë“œë°±ì„ ìš”ì²­í•˜ì—¬ ê´‘ê³  ë¬¸êµ¬ ë¹„êµ"""
    logging.info(f"ğŸ” ëª¨ë¸ í”¼ë“œë°± ìš”ì²­: ad1='{ad1_text}', ad2='{ad2_text}'")

    preset_text = [
        {
            "role": "system",
            "content": f"ì•„ë˜ëŠ” ê°™ì€ ì†Œì„¤ì— ëŒ€í•œ ë‘ ê°€ì§€ í™ë³´ ë¬¸êµ¬ì…ë‹ˆë‹¤.\n"
            f'1ë²ˆ ë¬¸êµ¬: "{ad1_text}"\n'
            f'2ë²ˆ ë¬¸êµ¬: "{ad2_text}"\n'
            f"ë‘ ë¬¸êµ¬ ì¤‘ ì‚¬ìš©ìì˜ í‰ê°€ ì ìˆ˜ê°€ ë†’ì€ ë¬¸ì¥ì´ ì¢‹ì€ ë¬¸ì¥ì…ë‹ˆë‹¤.\n"
            f"ë‘ ë¬¸ì¥ ì¤‘ì— ì–´ë–¤ ë¬¸ì¥ì´ ì¢‹ì€ì§€ ë§í•˜ê³ , ê·¸ ì´ìœ ë¥¼ í•¨ê»˜ ë§í•˜ì„¸ìš”.",
        },
        {
            "role": "user",
            "content": f'"ad1": {{"text": "{ad1_text}", "likes": {ad1_likes}}}, '
            f'"ad2": {{"text": "{ad2_text}", "likes": {ad2_likes}}}',
        },
    ]

    request_data = {
        "messages": preset_text,
        "topP": 0.8,
        "topK": 0,
        "maxTokens": 256,
        "temperature": 0.5,
        "repeatPenalty": 5.0,
        "stopBefore": [],
        "includeAiFilters": True,
        "seed": 0,
    }

    response = completion_executor.execute(request_data)

    if response:
        logging.info(f"âœ… ëª¨ë¸ ì‘ë‹µ: {response}")
    else:
        logging.warning(f"âš ï¸ ëª¨ë¸ ì‘ë‹µ ì—†ìŒ: ad1='{ad1_text}', ad2='{ad2_text}'")
        response = "ëª¨ë¸ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    return response


def generate_qa_data_with_comparison(ads_comparison, completion_executor):
    """QA ë°ì´í„°ì…‹ ìƒì„±"""
    qa_dataset = []
    logging.info(f"ğŸ“Œ {len(ads_comparison)}ê°œì˜ ê´‘ê³  ë¬¸êµ¬ ë¹„êµ ì‹œì‘...")

    for c_id, comparison in enumerate(ads_comparison):
        ad1 = comparison["ad1"]
        ad2 = comparison["ad2"]

        question = (
            f"ë‹¤ìŒì€ ê°™ì€ ì†Œì„¤ì— ëŒ€í•œ ë‘ ê°€ì§€ í™ë³´ ë¬¸êµ¬ì…ë‹ˆë‹¤.\n"
            f"1ë²ˆ: \"{ad1['text']}\" (ì¢‹ì•„ìš” {ad1['likes']}ê°œ)\n"
            f"2ë²ˆ: \"{ad2['text']}\" (ì¢‹ì•„ìš” {ad2['likes']}ê°œ)\n"
            f"ì–´ë–¤ ë¬¸êµ¬ê°€ ì‚¬ìš©ìì—ê²Œ ë” íš¨ê³¼ì ì¸ í™ë³´ íš¨ê³¼ë¥¼ ë³´ì˜€ì„ê¹Œìš”?"
        )
        logging.info(f"ğŸ“Œ {c_id + 1}/{len(ads_comparison)} ë¹„êµ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n {question}")

        # ëª¨ë¸ í”¼ë“œë°± ìš”ì²­
        feedback = get_feedback_from_model(completion_executor, ad1["text"], ad2["text"], ad1["likes"], ad2["likes"])

        # í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
        if ad2["likes"] > ad1["likes"]:
            answer = f"2ë²ˆ ë¬¸êµ¬ê°€ ë” íš¨ê³¼ì ì´ì—ˆìŠµë‹ˆë‹¤. ì´ìœ : {feedback}"
        else:
            answer = f"1ë²ˆ ë¬¸êµ¬ê°€ ë” íš¨ê³¼ì ì´ì—ˆìŠµë‹ˆë‹¤. ì´ìœ : {feedback}"

        logging.info(f"âœ… {c_id + 1}/{len(ads_comparison)} ë¹„êµ ì™„ë£Œ - ì •ë‹µ ìƒì„±")

        qa_dataset.append({"C_ID": c_id, "T_ID": 0, "Text": question, "Completion": answer})

    logging.info("ğŸ¯ QA ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")

    # CSV ì €ì¥ í™•ì¸
    df = pd.DataFrame(qa_dataset)
    df.to_csv("hyperclovax_ab_feedback_dataset.csv", index=False, encoding="utf-8")
    logging.info("âœ… ë°ì´í„°ì…‹ CSV ì €ì¥ ì™„ë£Œ: hyperclovax_ab_feedback_dataset.csv")

    return qa_dataset
