import os
import sys

import pandas as pd
import streamlit as st


sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import csv

from loguru import logger
from modules_common.load_config import load_config
import requests
from sentence_generator.modules.sentence_generate import run_sg
from sentence_generator.modules.sentence_generate_eval import run_sg_eval
from tqdm import tqdm


def load_original_texts(file_path):
    """
    novel_contents.csv íŒŒì¼ì—ì„œ tcontent,id ì»¬ëŸ¼ì„ ì½ì–´ì™€ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    """
    try:
        df = pd.read_csv(file_path)
        if "tcontent" not in df.columns or "id" not in df.columns:
            raise ValueError("CSV íŒŒì¼ì— 'tcontent' ë˜ëŠ” 'id' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return df["tcontent"].dropna().astype(str).tolist(), df["id"].tolist()
    except Exception as e:
        logger.error(f"Error loading original texts: {e}")
        sys.exit(1)


def generate_n_sentences(original_text, num_sentences, threshold_proba, threshold_correctness):
    """
    ë¬¸ì¥ì„ ìƒì„±í•˜ê³  í‰ê°€í•˜ì—¬ ì¼ì • ì ìˆ˜ ì´ìƒì¼ ê²½ìš° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜.
    """
    generated_texts = []
    index = 0
    trial = 0
    while len(generated_texts) < num_sentences:
        generated_text = run_sg(original_text, index)
        eval_result = run_sg_eval(original_text, generated_text)
        sum_scores, proba_score, sum_proba_scores = eval_result

        if (
            sum_proba_scores is not None
            and sum_proba_scores >= threshold_proba
            and proba_score[0] >= threshold_correctness
        ):
            generated_texts.append(generated_text.replace("\n", " ").replace('"  "', " "))
            index += 1
        else:
            logger.warning("Score below threshold. Retrying...")
            trial += 1
            if trial > 4:
                index += 1
    return generated_texts


def save_generated_sentences(id, generated_texts, output_file_path):
    """
    ìƒì„±ëœ ë¬¸ì¥ì„ CSV íŒŒì¼ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    """
    new_df = pd.DataFrame([{"id": id, **{f"sentence{i + 1}": text for i, text in enumerate(generated_texts)}}])
    try:
        existing_df = pd.read_csv(output_file_path)
        updated_df = pd.concat([existing_df, new_df], ignore_index=True)
    except FileNotFoundError:
        updated_df = pd.DataFrame(new_df)
    updated_df.to_csv(output_file_path, index=False)
    logger.info("âœ… Saved generated sentences")


def send_generated_sentences(file_path):
    """CSV ë°ì´í„°ë¥¼ APIë¡œ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜."""
    config_api = load_config("../config/config_api.yaml")
    URL = config_api["SERVER"]["URL"]
    ADMIN_CODE = config_api["SERVER"]["ADMIN_CODE"]

    with open(file_path, "r", encoding="utf-8") as file:
        data_list = list(csv.DictReader(file))
    success_count = 0

    st.success("ğŸš— APIë¡œ ì´ë™ ì¤‘...")

    for row in data_list:
        novel_id = row.get("id")
        for i in range(1, 2):
            content = row.get(f"sentence{i}")
            if not content:
                continue
            data = {"admin_code": ADMIN_CODE, "shorts_data": {"novel_id": int(novel_id), "content": content}}
            response = requests.post(f"{URL}/admin/shorts", json=data, verify=False)
            if response.status_code == 200:
                success_count += 1
            else:
                logger.error(f"Failed to send - novel_id: {novel_id}, Status Code: {response.status_code}")
    logger.info(f"âœ… Successfully sent {success_count} sentences.")


def main():
    st.set_page_config(page_title="ğŸ“– Novel Processing App", layout="wide")
    st.sidebar.image("../logo.png", use_container_width=True)

    st.sidebar.title("ğŸ“Œ Menu")
    page = st.sidebar.radio("ğŸ“‚ Select Page", ["ğŸ“¤ Upload Novel File", "âœï¸ Regenerate Novel Sentences"])
    if page == "ğŸ“¤ Upload Novel File":
        upload_page()
    elif page == "âœï¸ Regenerate Novel Sentences":
        regenerate_page()


def upload_page():
    st.title("ğŸ“¤ Upload Novel CSV File")
    uploaded_file = st.file_uploader("ğŸ“‚ Upload CSV File", type=["csv"])

    # íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ í•¨ìˆ˜ ì¢…ë£Œ
    if uploaded_file is None:
        st.warning("Please upload a CSV file.")
        return

    st.success("File uploaded successfully!")

    # íŒŒì¼ì„ ì½ì–´ì„œ ì²˜ë¦¬
    original_texts, ids = load_original_texts(uploaded_file)
    if not original_texts:
        st.error("No valid text found in the uploaded file.")
        return

    if st.button("ğŸš€ Start Process"):
        st.success("ğŸƒâ€â™‚ï¸â€â¡ï¸ Processing started!")
        output_file_path = "output_novel_content.csv"
        for original_text, id_value in tqdm(
            zip(original_texts, ids), desc="Generating sentences", total=len(original_texts)
        ):
            generated_texts = generate_n_sentences(original_text, 1, 20, 6.0)
            save_generated_sentences(id_value, generated_texts, output_file_path)

        send_generated_sentences("output_novel_content.csv")
        st.success("ğŸ‰ Processing completed and results saved.ğŸ‰")


def regenerate_page():
    st.title("Regenerate Novel Sentences")
    upload_period = st.date_input("Select Novel Upload Period", [])
    threshold_score = st.number_input("Enter Threshold Score", min_value=0, max_value=100, value=50)
    if st.button("Start Process"):
        st.success(f"âœ… Processing started with upload period {upload_period} and threshold score {threshold_score}!")


if __name__ == "__main__":
    main()
